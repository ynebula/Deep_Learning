{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 미니 배치\n",
    "- 전체 데이터를 하나의 행렬로 선언면, 전체 데이터에 대해서 경사 하강법을 수행하여 학습함\n",
    "- 방대한 현업 데이터를 하나의 행렬에 저장하면 비용함수 및 경사 하강법은 메모리 부족을 적용할 수 없음\n",
    "\n",
    "#### 미니 배치란\n",
    "- 전체 데이터를 작은 단위로 나누어서 단위별로 학습하는 방법\n",
    "- 미니 배치 학습을 하게되면 미니 배치만큼만 가져가서 미니 배치에 대한 대한 비용(cost)를 계산하고, 경사 하강법을 수행\n",
    "- 이렇게 모든 미니 배치가 완료되면, 전체 데이터에 대한 학습이 1회 끝나면 1 에포크(Epoch)가 끝나게 됩니다.\n",
    "\n",
    "배치 경사 하강법은 경사 하강법을 할 때, 전체 데이터를 사용하므로 가중치 값이 최적값에 수렴하는 과정이 매우 안정적이지만, 계산량이 너무 많이 듭니다. \n",
    "미니 배치 경사 하강법은 경사 하강법을 할 때, 전체 데이터의 일부만을 보고 수행하므로 최적값으로 수렴하는 과정에서 값이 조금 헤매기도 하지만 훈련 속도가 빠릅니다.\n",
    "\n",
    "#### 이터레이션(Iteration)\n",
    "![nn](https://wikidocs.net/images/page/36033/batchandepochiteration.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로드하기(Data Load)\n",
    "파이토치에서는 데이터를 다루기 위해 데이터셋(Dataset)과 데이터로더(DataLoader)를 제공합니다. \n",
    "- 미니 배치 학습\n",
    "- 데이터 셔플(shuffle)\n",
    "- 병렬 처리\n",
    "\n",
    "#### 사용 방법\n",
    "- Dataset을 정의\n",
    "- 정의된 Dataset을 DataLoader에 전달하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorDataset과 DataLoader를 임포트합니다.\n",
    "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
    "from torch.utils.data import DataLoader # 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorDataset은 텐서를 입력 받음\n",
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  90], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "\n",
    "dataset = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋, \n",
    "# batch_size: 미니 배치의 크기\n",
    "# shuffle=True를 선택하면 Epoch마다 데이터셋을 섞어서 데이터가 학습되는 순서를 바꿉니다.\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델과 옵티마이저\n",
    "model = nn.Linear(3,1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost: 22773.062500\n",
      "Epoch    0/20 Batch 2/3 Cost: 9890.560547\n",
      "Epoch    0/20 Batch 3/3 Cost: 3286.645020\n",
      "Epoch    1/20 Batch 1/3 Cost: 531.038208\n",
      "Epoch    1/20 Batch 2/3 Cost: 362.552063\n",
      "Epoch    1/20 Batch 3/3 Cost: 63.329159\n",
      "Epoch    2/20 Batch 1/3 Cost: 21.645264\n",
      "Epoch    2/20 Batch 2/3 Cost: 9.169369\n",
      "Epoch    2/20 Batch 3/3 Cost: 0.491278\n",
      "Epoch    3/20 Batch 1/3 Cost: 1.742851\n",
      "Epoch    3/20 Batch 2/3 Cost: 2.364782\n",
      "Epoch    3/20 Batch 3/3 Cost: 0.111393\n",
      "Epoch    4/20 Batch 1/3 Cost: 1.713829\n",
      "Epoch    4/20 Batch 2/3 Cost: 0.281997\n",
      "Epoch    4/20 Batch 3/3 Cost: 2.478357\n",
      "Epoch    5/20 Batch 1/3 Cost: 0.224336\n",
      "Epoch    5/20 Batch 2/3 Cost: 1.545010\n",
      "Epoch    5/20 Batch 3/3 Cost: 3.384408\n",
      "Epoch    6/20 Batch 1/3 Cost: 0.660739\n",
      "Epoch    6/20 Batch 2/3 Cost: 1.444978\n",
      "Epoch    6/20 Batch 3/3 Cost: 3.779374\n",
      "Epoch    7/20 Batch 1/3 Cost: 0.125499\n",
      "Epoch    7/20 Batch 2/3 Cost: 2.663284\n",
      "Epoch    7/20 Batch 3/3 Cost: 2.552749\n",
      "Epoch    8/20 Batch 1/3 Cost: 0.165278\n",
      "Epoch    8/20 Batch 2/3 Cost: 1.137391\n",
      "Epoch    8/20 Batch 3/3 Cost: 3.765267\n",
      "Epoch    9/20 Batch 1/3 Cost: 0.536276\n",
      "Epoch    9/20 Batch 2/3 Cost: 1.221503\n",
      "Epoch    9/20 Batch 3/3 Cost: 3.038887\n",
      "Epoch   10/20 Batch 1/3 Cost: 0.831286\n",
      "Epoch   10/20 Batch 2/3 Cost: 0.910329\n",
      "Epoch   10/20 Batch 3/3 Cost: 3.001127\n",
      "Epoch   11/20 Batch 1/3 Cost: 0.895491\n",
      "Epoch   11/20 Batch 2/3 Cost: 2.229505\n",
      "Epoch   11/20 Batch 3/3 Cost: 0.049964\n",
      "Epoch   12/20 Batch 1/3 Cost: 0.764002\n",
      "Epoch   12/20 Batch 2/3 Cost: 1.911799\n",
      "Epoch   12/20 Batch 3/3 Cost: 0.758937\n",
      "Epoch   13/20 Batch 1/3 Cost: 0.602650\n",
      "Epoch   13/20 Batch 2/3 Cost: 1.099264\n",
      "Epoch   13/20 Batch 3/3 Cost: 3.334179\n",
      "Epoch   14/20 Batch 1/3 Cost: 0.849275\n",
      "Epoch   14/20 Batch 2/3 Cost: 1.673638\n",
      "Epoch   14/20 Batch 3/3 Cost: 2.272578\n",
      "Epoch   15/20 Batch 1/3 Cost: 2.252306\n",
      "Epoch   15/20 Batch 2/3 Cost: 0.603022\n",
      "Epoch   15/20 Batch 3/3 Cost: 1.562767\n",
      "Epoch   16/20 Batch 1/3 Cost: 1.445156\n",
      "Epoch   16/20 Batch 2/3 Cost: 2.049894\n",
      "Epoch   16/20 Batch 3/3 Cost: 0.571208\n",
      "Epoch   17/20 Batch 1/3 Cost: 2.101029\n",
      "Epoch   17/20 Batch 2/3 Cost: 1.840168\n",
      "Epoch   17/20 Batch 3/3 Cost: 0.457671\n",
      "Epoch   18/20 Batch 1/3 Cost: 1.668269\n",
      "Epoch   18/20 Batch 2/3 Cost: 1.530457\n",
      "Epoch   18/20 Batch 3/3 Cost: 0.004636\n",
      "Epoch   19/20 Batch 1/3 Cost: 2.249639\n",
      "Epoch   19/20 Batch 2/3 Cost: 0.273785\n",
      "Epoch   19/20 Batch 3/3 Cost: 0.801115\n",
      "Epoch   20/20 Batch 1/3 Cost: 0.708931\n",
      "Epoch   20/20 Batch 2/3 Cost: 2.383250\n",
      "Epoch   20/20 Batch 3/3 Cost: 0.756201\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "  for batch_idx, samples in enumerate(dataloader):\n",
    "    # print(batch_idx)\n",
    "    # print(samples)\n",
    "    x_train, y_train = samples\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 계산\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
    "        cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[152.2071]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
